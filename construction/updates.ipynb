{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "from fastparquet import ParquetFile\n",
    "import time\n",
    "from time import sleep\n",
    "import librosa\n",
    "from vagalume import lyrics\n",
    "import difflib as di"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the organization data\n",
    "The analysis is done for  evaluate the distribution of songs by fold and by time range.\n",
    " the entire dataset and for the subset of songs evaluated manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L=pd.read_csv('lyrics_preprocessing_spotify_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo bins distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.set()\n",
    "\n",
    "data_1000 =data_GI_FO_AF_AA_L.copy()\n",
    "data_1000 = data_GI_FO_AF_AA_L.dropna(subset=['manual_filt'])\n",
    "ax = sns.histplot(data_GI_FO_AF_AA_L.tempo_bins, \n",
    "                  bins = 14,color = \"darkorange\")\n",
    "\n",
    "ax = sns.histplot(data_1000.tempo_bins, \n",
    "                  bins = 14,color = \"purple\")\n",
    "plt.axhline(y=100, color='k', linestyle=':',linewidth=3)\n",
    "ax.figure.set_size_inches(16, 6)\n",
    "ax.set_ylabel('Frequência', fontsize=14)\n",
    "ax.set_xlabel('BPM', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folds distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.set()\n",
    "\n",
    "data_1000 =data_GI_FO_AF_AA_L.copy()\n",
    "data_1000 = data_GI_FO_AF_AA_L.dropna(subset=['manual_filt'])\n",
    "ax = sns.histplot(data_GI_FO_AF_AA_L.folds, \n",
    "                  bins = 20,color = \"darkorange\")\n",
    "\n",
    "ax = sns.histplot(data_1000.folds, \n",
    "                  bins = 20,color = \"purple\")\n",
    "plt.axhline(y=50, color='k', linestyle=':',linewidth=3)\n",
    "ax.figure.set_size_inches(16, 6)\n",
    "ax.set_ylabel('Frequência', fontsize=14)\n",
    "ax.set_xlabel('BPM', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tempo bins and folds distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "ax = sns.histplot(data_GI_FO_AF_AA_L, x=\"tempo_bins\", hue='folds',multiple=\"dodge\",palette= \"Oranges\")\n",
    "ax = sns.histplot(data_1000, x=\"tempo_bins\", hue='folds',multiple=\"dodge\",palette= \"Purples\")\n",
    "ax.figure.set_size_inches(16, 6)\n",
    "plt.axhline(y=5, color='b', linestyle=':',linewidth=3)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "ax.set_xlabel('Tempo bins', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of analysis data\n",
    "Problem found! Analysis data should be in list format, not string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L.bars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L['bars'] = data_GI_FO_AF_AA_L['bars'].apply(ast.literal_eval)\n",
    "data_GI_FO_AF_AA_L['beats'] = data_GI_FO_AF_AA_L['beats'].apply(ast.literal_eval)\n",
    "data_GI_FO_AF_AA_L['tatums'] = data_GI_FO_AF_AA_L['tatums'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L.bars[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Problem solved \n",
    "But this problem occurs with the .csv format. So we will save the file in .parq too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L.to_parquet('forroset_update1.parq',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Simplifying access to analysis data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apeend_data(data,dado):\n",
    "    starts= []\n",
    "    duration = []\n",
    "    confidence = []\n",
    "    for j in range(len(dado)):\n",
    "        starts.append(dado[j]['start'])\n",
    "        duration.append(dado[j]['duration'])\n",
    "        confidence.append(dado[j]['confidence'])\n",
    "    data.append(starts)\n",
    "    data.append(duration)\n",
    "    data.append(confidence)\n",
    "    return data\n",
    "    \n",
    "music_ana = []\n",
    "for i in range(len(data_GI_FO_AF_AA_L['beats'])):\n",
    "    data = []\n",
    "    \n",
    "    beats = data_GI_FO_AF_AA_L['beats'][i]\n",
    "    bars = data_GI_FO_AF_AA_L['bars'][i]\n",
    "    tatums =data_GI_FO_AF_AA_L['tatums'][i]\n",
    "    data.append(data_GI_FO_AF_AA_L['track_id'][i])\n",
    "    data = apeend_data(data,beats)\n",
    "    data = apeend_data(data,bars)\n",
    "    data = apeend_data(data,tatums)\n",
    "    \n",
    "    music_ana.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= ['track_id','beats_start','beats_duration','beats_confidence','bars_start','bars_duration','bars_confidence','tatums_start','tatums_duration','tatums_confidence']\n",
    "data_analises = pd.DataFrame(music_ana,columns =columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L=data_GI_FO_AF_AA_L.drop(columns=[\"beats\",\"bars\",\"tatums\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L = data_GI_FO_AF_AA_L.merge(data_analises , how='left',on= \"track_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L.to_parquet('forroset_update1.parq',index = False)\n",
    "data_GI_FO_AF_AA_L.to_csv('forroset_update1.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting librosa beats anotation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mp3 import getMusics\n",
    "\n",
    "tempo_inicial = time.time()\n",
    "getMusics('forroset_update1.csv', 'files')\n",
    "tempo_final = time.time()\n",
    "duracao = tempo_final - tempo_inicial\n",
    "print(duracao/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forroset = ParquetFile('forroset_update1.parq')\n",
    "forroset = forroset.to_pandas()\n",
    "\n",
    "musics = os.listdir(\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librosa beats data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performing beats detection\n",
    "beat_frames_obt = []\n",
    "for music in musics:\n",
    "    filename = (\"/files/{}\").format(music)\n",
    "    y, sr = librosa.load(filename)\n",
    "    onset_env = librosa.onset.onset_strength(y, sr=sr,aggregate=np.median)\n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr, onset_envelope= onset_env, start_bpm = forroset.loc[forroset['track_id'] == music.split(\".\")[0]].tempo.tolist()[0])\n",
    "    beat_frames_obt.append([beat_frames, music.split(\".\")[0]])\n",
    "## Turning beat frames obtained into time\n",
    "for i in range(len(beat_frames_obt)):\n",
    "    beat_frames_obt[i][0] = librosa.frames_to_time(beat_frames_obt[i][0], sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjusting the decimal digits of the beats obtained by Librosa\n",
    "for i in range(len(beat_frames_obt)):\n",
    "    for j in range(len(beat_frames_obt[i][0])):\n",
    "        beat_frames_obt[i][0][j] = round(beat_frames_obt[i][0][j], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a DataFrame containing the list of detected beats and the respective identifier for each song\n",
    "updates = pd.DataFrame(data = beat_frames_obt, columns = [\"librosa_beats_start\", \"track_id\"])\n",
    "## Adding Updates to the forroset\n",
    "updated_forroset = forroset.merge(updates, how='left',on='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating the discrepancy measure of the beats obtained by Librosa\n",
    "discrepancies = []\n",
    "averages_spotify = []\n",
    "## Listing the average distances of the beats obtained by the spotify API\n",
    "for beats_list in updated_forroset['beats_start']:\n",
    "    mean = sum(beatsDistances(beats_list))/len(beatsDistances(beats_list))\n",
    "    averages_spotify.append(mean)\n",
    "## Listing the average distances of the beats obtained by Librosa\n",
    "averages_librosa = []\n",
    "for beats_list in updated_forroset[\"librosa_beats_start\"]:\n",
    "    beats_dist = beatsDistances(beats_list)\n",
    "    if len(beats_dist) != 0:\n",
    "        mean = sum(beats_dist)/len(beats_dist)\n",
    "        averages_librosa.append(mean)\n",
    "    else:\n",
    "        averages_librosa.append(None)\n",
    "## Calculating discrepancy measure\n",
    "for i in range(len(averages_spotify)):\n",
    "    if averages_librosa[i] == None:\n",
    "        discrepancies.append(None)\n",
    "    else:\n",
    "        discrepancy = abs((averages_librosa[i] - averages_spotify[i]))/averages_spotify[i]\n",
    "        ## Adjusting the decimal digits of the discrepancy indices\n",
    "        discrepancies.append(round(discrepancy,5))\n",
    "## Adding a column of discrepancy indices\n",
    "\n",
    "updated_forroset['librosa_discrepancy'] = discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beats_list = []\n",
    "for i in range(0,len(updated_forroset)):\n",
    "    if updated_forroset['librosa_discrepancy'][i] == None:\n",
    "        beats_list.append(None)\n",
    "    else:\n",
    "        beats_list.append(forroset_up['librosa_beats_start'][i])\n",
    "        \n",
    "updated_forroset['librosa_beats_start'] = beats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_forroset.to_parquet('forroset_update1.parq',index = False)\n",
    "updated_forroset.to_csv('forroset_update1.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of lyrics data\n",
    "Problem found! Lyrics data should be in list format, not string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L = ParquetFile('forroset_update1.parq')\n",
    "data_GI_FO_AF_AA_L = data_GI_FO_AF_AA_L.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_GI_FO_AF_AA_L.lyrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics =  data_GI_FO_AF_AA_L[[\"track_id\",'lyrics']].dropna()\n",
    "lyrics['lyrics'] = lyrics['lyrics'].apply(ast.literal_eval)\n",
    "data_GI_FO_AF_AA_L= data_GI_FO_AF_AA_L.drop(['lyrics','lyrics_confidence'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forroset = data_GI_FO_AF_AA_L.merge(lyrics, how='left',on= \"track_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem solved \n",
    "Same problem that occurred with the analysis data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forroset.lyrics[1][0])\n",
    "print()\n",
    "print(forroset.lyrics[1][1])\n",
    "print()\n",
    "print(forroset.lyrics[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAIR's compilance problems\n",
    "According to Vagalume API requirements it is necessary to insert the link of the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_data = forroset[['lyrics']].values \n",
    "\n",
    "letra = []\n",
    "list_error = []\n",
    "similarity = []\n",
    "url = []\n",
    "k=0\n",
    "j=0\n",
    "for i in range(0,len(lyrics_data)): \n",
    "    \n",
    "    time.sleep(2)\n",
    "    if i%50 ==0:\n",
    "        print(\"Waiting a little bit.\")\n",
    "        print(\"Lyrics searched: \", i)\n",
    "        print(\"Downloaded lyrics: \", k)\n",
    "        time.sleep(5)\n",
    "    \n",
    "    if lyrics_data[i][0] != None:\n",
    "        artist_name = lyrics_data[i][0][1]\n",
    "        song_name = lyrics_data[i][0][0]\n",
    "\n",
    "        try:\n",
    "            result = lyrics.find(artist_name, song_name)\n",
    "\n",
    "            if result.is_not_found():\n",
    "                letra.append(None)\n",
    "                similarity.append(None)\n",
    "            else:\n",
    "                s_artist = di.SequenceMatcher(None, artist_name.upper(), result.artist.name.upper()).ratio()\n",
    "                s_name = di.SequenceMatcher(None, song_name.upper(), result.song.name.upper()).ratio()\n",
    "                similarity.append({'name_similarity':s_name, 'artist_similarity':s_artist})\n",
    "                 \n",
    "                if s_name<1 or s_artist<1:\n",
    "                    print(s_name, s_artist,song_name.upper(), result.song.name.upper())\n",
    "                letra.append([result.song.name, result.artist.name,result.song.lyric,result.song.url])\n",
    "                url.append(result.song.url)\n",
    "                k+=1\n",
    "\n",
    "        except:\n",
    "            letra.append(None)\n",
    "            similarity.append(None)\n",
    "            url.append(None)\n",
    "            time.sleep(5)\n",
    "    else: \n",
    "        letra.append(None)\n",
    "        similarity.append(None)\n",
    "        url.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forroset['lyrics']=letra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final forroset version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forroset =forroset[['track_id', 'track', 'artist', 'artist_id', 'popularity', 'album',\n",
    "       'album_id', 'track_year', 'duration_ms', 'uri', 'preview_url', \n",
    "                                \n",
    "        'energy','liveness', 'tempo', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "       'time_signature', 'danceability', 'key', 'loudness', 'valence', 'mode',\n",
    "        \n",
    "       'beats_start', 'beats_duration', 'beats_confidence', 'bars_start',\n",
    "       'bars_duration', 'bars_confidence', 'tatums_start', 'tatums_duration',\n",
    "       'tatums_confidence','librosa_beats_start','librosa_discrepancy', \n",
    "                                \n",
    "       'tempo_bins', 'tempo_bins_max', 'genre_filt', 'folds','manual_filt', \n",
    "        \n",
    "        'lyrics' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forroset.to_parquet('forroset.parq',index = False)\n",
    "forroset.to_csv('forroset.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
